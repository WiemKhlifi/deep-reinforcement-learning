{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition\n",
    "\n",
    "---\n",
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import torch\n",
    "from maddpg_agent import MaddpgAgent\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Start the Environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"Tennis_Windows_x86_64\\Tennis.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, two agents control rackets to bounce a ball over a net. If an agent hits the ball over the net, it receives a reward of +0.1.  If an agent lets a ball hit the ground or hits the ball out of bounds, it receives a reward of -0.01.  Thus, the goal of each agent is to keep the ball in play.\n",
    "\n",
    "The observation space consists of 8 variables corresponding to the position and velocity of the ball and racket. Two continuous actions are available, corresponding to movement toward (or away from) the net, and jumping. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -6.65278625 -1.5\n",
      " -0.          0.          6.83172083  6.         -0.          0.        ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 24)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])\n",
    "states.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train MaddpgAgent Agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "agent = MaddpgAgent(state_size=state_size, action_size=action_size, seed=seed, n_agents=num_agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maddpg(agent, env, max_t=1000, window_size=100, score_threshold=0.5, print_interval=100, episodes=5000):\n",
    "    \n",
    "    # Initialize deque to store episode scores\n",
    "    scores_deque = deque(maxlen=window_size) \n",
    "    # Initialize list to store all episode scores\n",
    "    scores = []  \n",
    "    \n",
    "    # Print a message indicating the start of training\n",
    "    print(\"Training on {} started...\".format(agent.device))\n",
    "    \n",
    "    # Loop through the specified number of episodes\n",
    "    for i_episode in range(1, episodes+1):\n",
    "        # Reset the environment and obtain initial state information\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        states = env_info.vector_observations\n",
    "        agent.reset()\n",
    "        # Initialize episode scores\n",
    "        episode_scores = np.zeros(num_agents) \n",
    "        \n",
    "        # Loop through the maximum number of time steps per episode\n",
    "        for _ in range(max_t):\n",
    "            # Select actions for the current states\n",
    "            actions = agent.act(states)\n",
    "            # Send the actions to the environment and receive the next states, rewards, and done information\n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            next_states = env_info.vector_observations\n",
    "            rewards = env_info.rewards\n",
    "            dones = env_info.local_done\n",
    "\n",
    "            # Update the agent based on the observed states, actions, rewards, and next states\n",
    "            #agent.step(states=states, actions=actions, rewards=rewards, next_states=next_states, dones=dones)\n",
    "            agent.step(states=states, actions=actions, rewards=[reward*110 if reward <0 else reward  for reward in rewards], next_states=next_states, dones=dones)\n",
    "            episode_scores += np.array(rewards)\n",
    "            states = next_states\n",
    "            # Break if any agent is done\n",
    "            if np.any(dones):\n",
    "                break\n",
    "\n",
    "        # Calculate the maximum score for the episode\n",
    "        episode_score = np.max(episode_scores) \n",
    "        # Append the episode score to the scores deque\n",
    "        scores_deque.append(episode_score)\n",
    "        # Append the episode score to the scores list\n",
    "        scores.append(episode_score)\n",
    "        # Calculate the average score\n",
    "        average_score = np.mean(scores_deque)\n",
    "\n",
    "        # Print the episode number, average score, local average score, current score, and all episode scores at specified intervals\n",
    "        if i_episode % print_interval == 0:\n",
    "            print('\\rEpisode: {}\\tAverage Score: {:.3f}\\tCurrent Score: {:.3f}\\tScores : {:.3f} {:.3f}'.format(i_episode, average_score, episode_score , *episode_scores))\n",
    "        \n",
    "        # Check if the score threshold is reached and print a message if so, then save the agent's state to a checkpoint file\n",
    "        if average_score >= score_threshold:\n",
    "            print('\\nEnvironment solved in {} episodes!\\tAverage Score: {:.3f}'.format(i_episode-window_size, average_score))\n",
    "            torch.save(agent.actor_local.state_dict(), 'checkpoint_actor_2_agents.pth')\n",
    "            torch.save(agent.critic_local.state_dict(), 'checkpoint_critic_2_agents.pth')\n",
    "            break\n",
    "    \n",
    "    # Save the scores to a numpy file\n",
    "    np.save('maddpg_scores.npy', scores)\n",
    "    # Return the scores\n",
    "    return scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:0 started...\n",
      "Episode: 50\tAverage Score: 0.002\tlocal average Score: 0.002\tCurrent Score: 0.000\tScores : -0.010 0.000\n",
      "Episode: 100\tAverage Score: 0.001\tlocal average Score: 0.000\tCurrent Score: 0.000\tScores : 0.000 -0.010\n",
      "Episode: 150\tAverage Score: 0.000\tlocal average Score: 0.000\tCurrent Score: 0.000\tScores : 0.000 -0.010\n",
      "Episode: 200\tAverage Score: 0.002\tlocal average Score: 0.004\tCurrent Score: 0.000\tScores : -0.010 0.000\n",
      "Episode: 250\tAverage Score: 0.002\tlocal average Score: 0.000\tCurrent Score: 0.000\tScores : 0.000 -0.010\n",
      "Episode: 300\tAverage Score: 0.000\tlocal average Score: 0.000\tCurrent Score: 0.000\tScores : 0.000 -0.010\n",
      "Episode: 350\tAverage Score: 0.000\tlocal average Score: 0.000\tCurrent Score: 0.000\tScores : 0.000 -0.010\n",
      "Episode: 400\tAverage Score: 0.000\tlocal average Score: 0.000\tCurrent Score: 0.000\tScores : -0.010 0.000\n",
      "Episode: 450\tAverage Score: 0.000\tlocal average Score: 0.000\tCurrent Score: 0.000\tScores : -0.010 0.000\n",
      "Episode: 500\tAverage Score: 0.000\tlocal average Score: 0.000\tCurrent Score: 0.000\tScores : 0.000 -0.010\n",
      "Episode: 550\tAverage Score: 0.000\tlocal average Score: 0.000\tCurrent Score: 0.000\tScores : -0.010 0.000\n",
      "Episode: 600\tAverage Score: 0.008\tlocal average Score: 0.015\tCurrent Score: 0.100\tScores : 0.100 -0.010\n",
      "Episode: 650\tAverage Score: 0.026\tlocal average Score: 0.036\tCurrent Score: 0.000\tScores : -0.010 0.000\n",
      "Episode: 700\tAverage Score: 0.053\tlocal average Score: 0.070\tCurrent Score: 0.090\tScores : 0.000 0.090\n",
      "Episode: 750\tAverage Score: 0.082\tlocal average Score: 0.094\tCurrent Score: 0.000\tScores : -0.010 0.000\n",
      "Episode: 800\tAverage Score: 0.107\tlocal average Score: 0.120\tCurrent Score: 0.000\tScores : -0.010 0.000\n",
      "Episode: 850\tAverage Score: 0.325\tlocal average Score: 0.529\tCurrent Score: 0.100\tScores : -0.010 0.100\n",
      "Episode: 900\tAverage Score: 0.456\tlocal average Score: 0.383\tCurrent Score: 0.100\tScores : 0.100 -0.010\n",
      "Episode: 950\tAverage Score: 0.413\tlocal average Score: 0.444\tCurrent Score: 0.100\tScores : -0.010 0.100\n",
      "Episode: 1000\tAverage Score: 0.405\tlocal average Score: 0.367\tCurrent Score: 0.300\tScores : 0.300 0.190\n",
      "Episode: 1050\tAverage Score: 0.419\tlocal average Score: 0.471\tCurrent Score: 0.300\tScores : 0.300 0.290\n",
      "\n",
      "Environment solved in 964 episodes!\tAverage Score: 0.501\n"
     ]
    }
   ],
   "source": [
    "scores = maddpg(agent, env, max_t=1000, window_size=100, score_threshold=0.5, print_interval=100, episodes=5000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a figure and axis for plotting\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "# Plot the scores over episodes\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "\n",
    "# Set labels for the axes\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "\n",
    "# Save the plot as an image file\n",
    "plt.savefig('maddpg_scores_plot_curve.png')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Run Inference mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = MaddpgAgent(state_size=state_size, action_size=action_size,random_seed=0)\n",
    "agent.actor_local.load_state_dict(torch.load('checkpoint_actor_2_agents.pth'))\n",
    "agent.critic_local.load_state_dict(torch.load('checkpoint_critic_2_agents.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8950000135228038\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]   \n",
    "states = env_info.vector_observations                  \n",
    "scores = np.zeros(num_agents)                         \n",
    "step = 0\n",
    "while step<1000:\n",
    "    step+=1\n",
    "    actions = agent.act(states)                   \n",
    "    env_info = env.step(actions)[brain_name]\n",
    "    next_states = env_info.vector_observations\n",
    "    rewards = env_info.rewards\n",
    "    dones = env_info.local_done\n",
    "    rewards = env_info.rewards               \n",
    "    done = env_info.local_done                  \n",
    "    scores += rewards                                \n",
    "    states = next_states                     \n",
    "    if np.any(dones):\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "39e381cf46b1f55053a25401b9ec0a7bf444799a815663fc9f4e7190e64d6089"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
